{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byH5N1HEopQ-"
   },
   "source": [
    "# **Load train data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZomOEm_SyL31"
   },
   "source": [
    "Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 16:54:36.012170: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constantes\n",
    "RNA_BASES = [[\"A\"], [\"U\"], [\"C\"], [\"G\"]]\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False).fit(RNA_BASES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./data/SN_filtered_train.csv\", header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5KhTQ-qwfbG"
   },
   "source": [
    "# **Exploratory Data Analysis (EDA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwgn5zFGws7F"
   },
   "source": [
    "To be completed: add analysis of shape of the data, pycharts, boxplots, pehaps PCA, univariate analysis, multivariate analysis..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "executionInfo": {
     "elapsed": 8093,
     "status": "ok",
     "timestamp": 1696108835445,
     "user": {
      "displayName": "Ghosty Science",
      "userId": "16741200961527128262"
     },
     "user_tz": -120
    },
    "id": "pFKZeActGokI",
    "outputId": "7410bd77-a330-45c1-eca4-7a3a276074f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>reads</th>\n",
       "      <th>signal_to_noise</th>\n",
       "      <th>SN_filter</th>\n",
       "      <th>reactivity_0001</th>\n",
       "      <th>reactivity_0002</th>\n",
       "      <th>reactivity_0003</th>\n",
       "      <th>...</th>\n",
       "      <th>reactivity_error_0197</th>\n",
       "      <th>reactivity_error_0198</th>\n",
       "      <th>reactivity_error_0199</th>\n",
       "      <th>reactivity_error_0200</th>\n",
       "      <th>reactivity_error_0201</th>\n",
       "      <th>reactivity_error_0202</th>\n",
       "      <th>reactivity_error_0203</th>\n",
       "      <th>reactivity_error_0204</th>\n",
       "      <th>reactivity_error_0205</th>\n",
       "      <th>reactivity_error_0206</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51e61fbde94d</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAACAUUGAUAUGGAUUUACUC...</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>15k_2A3</td>\n",
       "      <td>5326.0</td>\n",
       "      <td>1.933</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25ce8d5109cd</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAACCUUGAUAUGGAUUUACUC...</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>15k_2A3</td>\n",
       "      <td>4647.0</td>\n",
       "      <td>2.347</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07dcfb6d1965</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAACUUUGAUAUGGAUUUACUC...</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>15k_2A3</td>\n",
       "      <td>102843.0</td>\n",
       "      <td>11.824</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e561cc042a4c</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAACGAUGAUAUGGAUUUACUC...</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>15k_2A3</td>\n",
       "      <td>7665.0</td>\n",
       "      <td>3.519</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aa948762535f</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAACGCUGAUAUGGAUUUACUC...</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>15k_2A3</td>\n",
       "      <td>14018.0</td>\n",
       "      <td>3.219</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 419 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sequence_id                                           sequence  \\\n",
       "0  51e61fbde94d  GGGAACGACUCGAGUAGAGUCGAAAAACAUUGAUAUGGAUUUACUC...   \n",
       "1  25ce8d5109cd  GGGAACGACUCGAGUAGAGUCGAAAAACCUUGAUAUGGAUUUACUC...   \n",
       "2  07dcfb6d1965  GGGAACGACUCGAGUAGAGUCGAAAAACUUUGAUAUGGAUUUACUC...   \n",
       "3  e561cc042a4c  GGGAACGACUCGAGUAGAGUCGAAAAACGAUGAUAUGGAUUUACUC...   \n",
       "4  aa948762535f  GGGAACGACUCGAGUAGAGUCGAAAAACGCUGAUAUGGAUUUACUC...   \n",
       "\n",
       "  experiment_type dataset_name     reads  signal_to_noise  SN_filter  \\\n",
       "0         2A3_MaP      15k_2A3    5326.0            1.933          1   \n",
       "1         2A3_MaP      15k_2A3    4647.0            2.347          1   \n",
       "2         2A3_MaP      15k_2A3  102843.0           11.824          1   \n",
       "3         2A3_MaP      15k_2A3    7665.0            3.519          1   \n",
       "4         2A3_MaP      15k_2A3   14018.0            3.219          1   \n",
       "\n",
       "   reactivity_0001  reactivity_0002  reactivity_0003  ...  \\\n",
       "0              NaN              NaN              NaN  ...   \n",
       "1              NaN              NaN              NaN  ...   \n",
       "2              NaN              NaN              NaN  ...   \n",
       "3              NaN              NaN              NaN  ...   \n",
       "4              NaN              NaN              NaN  ...   \n",
       "\n",
       "   reactivity_error_0197  reactivity_error_0198  reactivity_error_0199  \\\n",
       "0                    NaN                    NaN                    NaN   \n",
       "1                    NaN                    NaN                    NaN   \n",
       "2                    NaN                    NaN                    NaN   \n",
       "3                    NaN                    NaN                    NaN   \n",
       "4                    NaN                    NaN                    NaN   \n",
       "\n",
       "   reactivity_error_0200  reactivity_error_0201  reactivity_error_0202  \\\n",
       "0                    NaN                    NaN                    NaN   \n",
       "1                    NaN                    NaN                    NaN   \n",
       "2                    NaN                    NaN                    NaN   \n",
       "3                    NaN                    NaN                    NaN   \n",
       "4                    NaN                    NaN                    NaN   \n",
       "\n",
       "   reactivity_error_0203  reactivity_error_0204  reactivity_error_0205  \\\n",
       "0                    NaN                    NaN                    NaN   \n",
       "1                    NaN                    NaN                    NaN   \n",
       "2                    NaN                    NaN                    NaN   \n",
       "3                    NaN                    NaN                    NaN   \n",
       "4                    NaN                    NaN                    NaN   \n",
       "\n",
       "   reactivity_error_0206  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  \n",
       "\n",
       "[5 rows x 419 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 rows of the DataFrame\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDm3n7BKw_oZ"
   },
   "source": [
    "# **Feature engeneering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8kB0ID6Z9De"
   },
   "source": [
    "Remove \"sequence_id\", \"dataset_name\", \"reads\", \"SN_filter\" and \"reactivity_error\" columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to keep rows with maximum signal_to_noise within identical sequences\n",
    "def filter_identical_sequences(df):\n",
    "    # Group by 'sequence' and keep the row with max 'signal_to_noise'\n",
    "    filtered_df = df.groupby('sequence').apply(lambda x: x.loc[x['signal_to_noise'].idxmax()])\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_from_data(data, keys_name=[\"2A3_MaP\", \"DMS_MaP\"]):\n",
    "    n_duplicate = sum(data.duplicated(subset=[\"sequence\", \"experiment_type\"]))\n",
    "    if n_duplicate > 0:\n",
    "        return None\n",
    "\n",
    "    seq_reactivity = dict()\n",
    "    for seq, group in data.groupby(\"sequence\"):\n",
    "        seq_reactivity[seq] = dict()\n",
    "        for key in keys_name:\n",
    "            mask = group[\"experiment_type\"] == key\n",
    "            seq_reactivity[seq][key] = group[mask].drop(\n",
    "                labels=[\"sequence\", \"experiment_type\"], axis=1\n",
    "            ).values.reshape(-1)\n",
    "            seq_reactivity[seq][key] = np.expand_dims(seq_reactivity[seq][key], axis=1)\n",
    "\n",
    "    return seq_reactivity\n",
    "\n",
    "def XY_from_dict(dict_data, encoder, maxlen=457):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for i, (sequence, reactivities) in enumerate(dict_data.items()):\n",
    "        y = np.hstack([reactivities[\"2A3_MaP\"], reactivities[\"DMS_MaP\"]])\n",
    "        x_list.append(onehot_from_sequence(sequence, encoder, maxlen=maxlen))\n",
    "        y_list.append(padded_matrix(y, maxlen=maxlen))\n",
    "    return np.array(x_list), np.array(y_list)\n",
    "\n",
    "def onehot_from_sequence(sequence, encoder, to_add=\"0\", maxlen=457):\n",
    "    \"\"\"sequence: str\"\"\"\n",
    "    if maxlen is None:\n",
    "        maxlen = 0\n",
    "    proccessed_sequence = sequence.upper()\n",
    "    proccessed_sequence += to_add * (maxlen - len(sequence))\n",
    "    proccessed_sequence = [[nbase] for nbase in proccessed_sequence]\n",
    "    onehot_sequence = encoder.transform(proccessed_sequence)\n",
    "    return onehot_sequence\n",
    "\n",
    "def padded_matrix(matrix_2d, maxlen=457):\n",
    "    if not isinstance(matrix_2d, np.ndarray):\n",
    "        matrix_2d = np.array(matrix_2d)\n",
    "\n",
    "    n_toadd = maxlen - matrix_2d.shape[0]\n",
    "    padding = ((0, n_toadd), (0, 0))  # padding on axis\n",
    "    matrix_2d_padded = np.pad(matrix_2d, pad_width=padding, mode=\"constant\")\n",
    "    return matrix_2d_padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "id": "DNji9XrsIFEv"
   },
   "outputs": [],
   "source": [
    "# Get columns name for X, and Y\n",
    "x_columns = [\"sequence_id\", \"sequence\"]\n",
    "conditional_columns = [\"experiment_type\", \"signal_to_noise\"]\n",
    "y_columns = [colname for colname in train_data.columns if re.match(\"^reactivity_[0-9]{4}$\", colname)]\n",
    "\n",
    "# Keep the necessary columns from the DataFrame\n",
    "cleaned_train_data = train_data[x_columns + conditional_columns + y_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqDa3YTXBZQ3"
   },
   "source": [
    "For each group of identical sequences, keep only the sequence with the highest signal to noise value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "id": "7zlSxgrf4_MP"
   },
   "outputs": [],
   "source": [
    "# Create two separate DataFrames based on \"experiment_type\"\n",
    "df_2A3_MaP = cleaned_train_data[cleaned_train_data['experiment_type'] == '2A3_MaP']\n",
    "df_DMS_MaP = cleaned_train_data[cleaned_train_data['experiment_type'] == 'DMS_MaP']\n",
    "\n",
    "# Delete cleaned_train_data to free space memory\n",
    "del cleaned_train_data\n",
    "\n",
    "df_2A3_MaP = filter_identical_sequences(df_2A3_MaP)  # Filter df_2A3_MaP\n",
    "df_DMS_MaP = filter_identical_sequences(df_DMS_MaP)  # Filter df_DMS_MaP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the two data frames\n",
    "mask_2A3 = df_2A3_MaP[\"sequence\"].isin(df_DMS_MaP[\"sequence\"])\n",
    "mask_DMS = df_DMS_MaP[\"sequence\"].isin(df_2A3_MaP[\"sequence\"])\n",
    "\n",
    "cleared_train_data = pd.concat([df_2A3_MaP[mask_2A3], df_DMS_MaP[mask_DMS]], ignore_index=True)\n",
    "cleared_train_data.drop(columns=['signal_to_noise'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PsUS4aNI5LP"
   },
   "source": [
    "Save the cleared train data into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns type\n",
    "cleared_train_data[y_columns] = cleared_train_data[y_columns].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "id": "RpY4-pTPI_bQ"
   },
   "outputs": [],
   "source": [
    "# Save cleared_train_data as a CSV file\n",
    "csv_path = './data/cleared_train_data.csv'\n",
    "cleared_train_data.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleared_train_data = train_data\n",
    "dict_data = dict_from_data(cleared_train_data)\n",
    "x, y = XY_from_dict(dict_data, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167979, 457, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167979, 457, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzQVMwJp-amx"
   },
   "source": [
    "# **Model**\n",
    "(To be corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZT7N2KAJfFO"
   },
   "source": [
    "Load cleared train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "id": "477pmJTr_Uoo"
   },
   "outputs": [],
   "source": [
    "# Define the path of the CSV file\n",
    "csv_path = './data/cleared_train_data.csv'\n",
    "\n",
    "# Load the CSV file as a DataFrame\n",
    "cleared_train_data = pd.read_csv(csv_path)\n",
    "dict_data = dict_from_data(cleared_train_data)\n",
    "x, y = XY_from_dict(dict_data, encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9PJMvm0KKkS"
   },
   "source": [
    "Define features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Masking, Reshape, Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle NaN values by creating a mask\n",
    "x_mask = x.sum(axis=2) == 0\n",
    "reactivity_mask = ~np.isnan(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "id": "Y-EtZee-KJ2j"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "x_train, x_val, y_train, y_val, mask_train, mask_val = train_test_split(\n",
    "    x, y, x_mask, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgJnPRBiKVSK"
   },
   "source": [
    "RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.nan_to_num(y_train)  # pour le moment on remplace les nan par des 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-05 16:06:44.117141: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-05 16:06:44.118478: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-05 16:06:44.119406: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-05 16:06:44.378558: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-05 16:06:44.380170: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-05 16:06:44.381406: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-05 16:06:44.866134: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-05 16:06:44.867513: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-05 16:06:44.868596: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.1313\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1299\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f91d1b5ea50>"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supposons que vous avez déjà créé votre masque de padding (padding_mask) comme indiqué précédemment.\n",
    "\n",
    "# Créez votre modèle\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(457, 4)),\n",
    "    keras.layers.LSTM(units=8, return_sequences=True),\n",
    "    keras.layers.Dense(units=2, activation='linear')\n",
    "])\n",
    "\n",
    "# Appliquez le masque de padding à la sortie de la couche LSTM\n",
    "#masked_output = keras.layers.Masking(mask_value=True)(model.output)\n",
    "\n",
    "# Créez un modèle final en utilisant la sortie masquée\n",
    "final_model = keras.Model(inputs=model.input, outputs=model.output)\n",
    "\n",
    "# Compilez et entraînez le modèle comme d'habitude\n",
    "final_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "final_model.fit(x_train, y_train, epochs=3, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.17378888, 0.01762347],\n",
       "        [0.27257285, 0.01585824],\n",
       "        [0.3257735 , 0.0079139 ],\n",
       "        ...,\n",
       "        [0.00706036, 0.01595702],\n",
       "        [0.00706036, 0.01595702],\n",
       "        [0.00706036, 0.01595702]],\n",
       "\n",
       "       [[0.17378888, 0.01762347],\n",
       "        [0.27257285, 0.01585824],\n",
       "        [0.3257735 , 0.0079139 ],\n",
       "        ...,\n",
       "        [0.00706036, 0.01595702],\n",
       "        [0.00706036, 0.01595702],\n",
       "        [0.00706036, 0.01595702]],\n",
       "\n",
       "       [[0.17378888, 0.01762347],\n",
       "        [0.27257285, 0.01585824],\n",
       "        [0.3257735 , 0.0079139 ],\n",
       "        ...,\n",
       "        [0.00706036, 0.01595702],\n",
       "        [0.00706036, 0.01595702],\n",
       "        [0.00706036, 0.01595702]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.17378888, 0.01762347],\n",
       "        [0.27257285, 0.01585824],\n",
       "        [0.3257735 , 0.0079139 ],\n",
       "        ...,\n",
       "        [0.00706036, 0.01595702],\n",
       "        [0.00706036, 0.01595702],\n",
       "        [0.00706036, 0.01595702]],\n",
       "\n",
       "       [[0.17378888, 0.01762347],\n",
       "        [0.27257285, 0.01585824],\n",
       "        [0.3257735 , 0.0079139 ],\n",
       "        ...,\n",
       "        [0.00706036, 0.01595702],\n",
       "        [0.00706036, 0.01595702],\n",
       "        [0.00706036, 0.01595702]],\n",
       "\n",
       "       [[0.17378888, 0.01762347],\n",
       "        [0.27257285, 0.01585824],\n",
       "        [0.3257735 , 0.0079139 ],\n",
       "        ...,\n",
       "        [0.00706036, 0.01595702],\n",
       "        [0.00706036, 0.01595702],\n",
       "        [0.00706036, 0.01595702]]], dtype=float32)"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./data/X.data\", x)\n",
    "np.save(\"./data/Y.data\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeaV2Er3_XEe"
   },
   "source": [
    "# **Load test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jyeZ3NFx_cXW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N16LwvGQ_cov"
   },
   "source": [
    "# **Check efficiency of the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5g3Fg3cc_s9-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6pvbufG_g3Y"
   },
   "source": [
    "# **Save submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSdj9uMq_tf4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rv5l23F3_lS5"
   },
   "source": [
    "# **Plot RNA structure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52s39bl1_uOQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPuzuUz8kVToq9n1Bq0a7oY",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
