{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "093e937d-6ef3-4849-8ed4-f93bdb929e2b",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3857b5f-7dbe-4a16-8f85-45fbb378375f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense, Masking, Reshape\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Masking, Reshape\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ffb93af-3006-47c0-b2bb-c5285accf643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define constant \n",
    "\n",
    "RNA_BASES = [[\"A\"], [\"U\"], [\"C\"], [\"G\"]]\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False).fit(RNA_BASES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "652452fa-fda3-41a6-9a3d-a567470a8c54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(file_path) :\n",
    "    \n",
    "    \"\"\"\n",
    "    Load data from a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The path to the CSV file containing the data.\n",
    "\n",
    "    Returns:\n",
    "    - data(DataFrame): A Pandas DataFrame containing the loaded data.\n",
    "    \"\"\"\n",
    "    file_path = input(\"Enter your file path:\")\n",
    "    data = pd.read.csv(file_path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a46aa1c6-9909-4bad-82a9-5084cf98a5ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_SN(data):\n",
    "    \n",
    "    \"\"\" \n",
    "    Filter the rows where \"SN_filter\" is equal to 1 \n",
    "       \n",
    "    Parameters :\n",
    "    -data(DataFrame) : A pandas Dataframe containing the input data\n",
    "    \n",
    "    Returns :\n",
    "    - cleaned_train_data(DataFrame) : A dataframe containing only the sequences that passed the SN_filter \n",
    "    \"\"\"\n",
    "    cleaned_train_data = data[data['SN_filter'] == 1]\n",
    "    return cleaned_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b9a7e2b-6a5b-4709-8e13-020005c5a0b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_identical_sequences(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    For identical sequences keep rows with maximum signal to noise\n",
    "    \n",
    "    Parameters:\n",
    "    -data (DataFrame) : pandas input dataframe\n",
    "    \n",
    "    Returns :\n",
    "    -filtered_df(Dataframe) : a filtered dataframe with the sequences with a maximum signal to noise\n",
    "    \"\"\"\n",
    "    \n",
    "    filtered_df = cleaned_train_data.groupby('sequence').apply(lambda x: x.loc[x['signal_to_noise'].idxmax()])\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e5a0fa3-dd4b-447f-892b-eb72d50f8dad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def columns_defining(cleaned_train_data) :\n",
    "    \n",
    "    \"\"\"\n",
    "    Define the X and Y columns\n",
    "    \n",
    "    Parameters:\n",
    "    -cleaned_trained_data (Dataframe) : pandas dataframe input\n",
    "    \n",
    "    Returns :\n",
    "    -x_columns(list) : column names for X\n",
    "    -y_columns(list) : column names for Y\n",
    "    -conditional_columns(list) : continonal columns for the whole dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    x_columns = [\"sequence_id\", \"sequence\"]\n",
    "    conditional_columns = [\"experiment_type\", \"signal_to_noise\"]\n",
    "    y_columns = [colname for colname in cleared_train_data.columns if re.match(\"^reactivity_[0-9]{4}$\", colname)]\n",
    "    return x_columns, y_columns, conditional_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c914bfcc-ab9c-4b16-9679-e16d5a333bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def column_filtering(cleaned_train_data, x_columns, y_columns, conditional_columns) :\n",
    "    \n",
    "    \"\"\"\n",
    "    Select the necessary columns in the dataframe\n",
    "    \n",
    "    Parameters :\n",
    "    -cleaned_train_data(DataFrame) : dataframe input\n",
    "    -x_columns(list): list of columns for X\n",
    "    -y_columns(list): list of columns for Y\n",
    "    -conditional_columns(list): list of conditional columns\n",
    "    \n",
    "    Returns : \n",
    "    -cleaned_train_data(DataFrame) : dataframe with X and Y columns and the co,nditional ones\n",
    "    \"\"\"\n",
    "    \n",
    "    cleaned_train_data = cleaned_train_data[x_columns + conditional_columns + y_columns]\n",
    "    return cleaned_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe1cfb70-10dd-49e5-9b22-dc4e4f2f02bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dataframe_separation(cleaned_train_data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create two dataframe based on the experiment type (DMS and 2A3)\n",
    "    \n",
    "    Parameters :\n",
    "    -cleaned_train_data(DataFrame) : input dataframe to be separated in two\n",
    "    \n",
    "    Returns :\n",
    "    -df_2A3_MaP(DataFrame) : dataframe with the 2A3 results only\n",
    "    -df_DMS_MaP(DataFrame) : dataframe with the DMS results only\n",
    "    \n",
    "    \"\"\"\n",
    "    df_2A3_MaP = cleaned_train_data[cleaned_train_data['experiment_type'] == '2A3_MaP']\n",
    "    df_DMS_MaP = cleaned_train_data[cleaned_train_data['experiment_type'] == 'DMS_MaP']\n",
    "    \n",
    "    # Delete cleaned_train_data to free space memory\n",
    "    del cleaned_train_data\n",
    "    \n",
    "    return df_2A3_MaP, df_DMS_MaP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbea94ea-e7a2-4cac-a7cb-a9dd4a7b358b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dataframe_concatenation(df_2A3_MaP, df_DMS_MaP) :\n",
    "    \n",
    "    \"\"\"\n",
    "    Concatenation of the experiment dataframes\n",
    "    \n",
    "    Parameters :\n",
    "    - df_2A3_MaP(DataFrame) : dataframe with the 2A3 experiment results\n",
    "    - df_DMS_MaP(DataFrame) : dataframe with the DMS experiment results\n",
    "    \n",
    "    Returns :\n",
    "    \n",
    "    -cleared_train_data(DataFrame) : concatenated dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    mask_2A3 = df_2A3_MaP[\"sequence\"].isin(df_DMS_MaP[\"sequence\"])\n",
    "    mask_DMS = df_DMS_MaP[\"sequence\"].isin(df_2A3_MaP[\"sequence\"])\n",
    "    \n",
    "    cleared_train_data = pd.concat([df_2A3_MaP[mask_2A3], df_DMS_MaP[mask_DMS]], ignore_index=True)\n",
    "    cleared_train_data = cleared_train_data.drop(columns=['signal_to_noise'], inplace=True)\n",
    "    \n",
    "    return cleared_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "538b661e-4bf4-4ee0-a414-14024045bc62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def csv_export(cleared_train_data, y_columns) :\n",
    "    \n",
    "    \"\"\"\n",
    "    Export the dataframe into a csv file\n",
    "    \n",
    "    Parameters : \n",
    "    - cleared_train_data(DataFrame) : dataframe with the whole data\n",
    "    - y_columns(list) : columns for Y data\n",
    "    \"\"\"\n",
    "    \n",
    "    #Convert the y columns     \n",
    "    cleared_train_data[y_columns] = cleared_train_data[y_columns].astype(np.float32)\n",
    "    \n",
    "    #export the csv\n",
    "    csv_path = input(\"Enter your path :\") \n",
    "    cleared_train_data.to_csv(csv_path, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6fcbe9d-d2fa-4f61-9512-55ae51682f02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extraction(data) :\n",
    "    \n",
    "    \"\"\"\n",
    "    Extract RNA sequences and experiment type\n",
    "    \n",
    "    Parameters :\n",
    "    - data(Dataframe) : preloaded dataframe with the right format\n",
    "    \n",
    "    Returns:\n",
    "    - rna_sequence(Series) : a pandas series with all the sequences\n",
    "    - experiment_type(Series) : a panda series with the experiment types\n",
    "    \"\"\"\n",
    "    \n",
    "    rna_sequences = data['sequence']\n",
    "    experiment_type = data['experiment_type']\n",
    "    \n",
    "    return rna_sequence, experiment_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f91079ea-b1cb-43af-b925-c18224d8e396",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def features_encoding(rna_sequences, experiment_type) :\n",
    "    \n",
    "    \"\"\"\n",
    "    Fit and transform RNA sequences\n",
    "    \n",
    "    Parameters :\n",
    "    - rna_sequence(Series) : a pandas series with all the RNA sequences\n",
    "    - experiment_type(Series) : a panda series with the experiment types\n",
    "    \n",
    "    Returns :\n",
    "    - features(matrix) : concatenated encoded matrix\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    encoder = OneHotEncoder(sparse_output = True, dtype=np.int64)\n",
    "    rna_sequences_encoded = encoder.fit_transform(rna_sequences.values.reshape(-1,1))\n",
    "    experiment_type_encoded = pd.get_dummies(experiment_type)\n",
    "    features = hstack((rna_sequences_encoded, experiment_type_encoded))\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8da5a9e1-a4cd-4ffe-ac59-2c3e0b8388ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_target(cleared_train_data) :\n",
    "    \n",
    "    \"\"\"\n",
    "    Extract reactivity columns as targets to use as Y\n",
    "    \n",
    "    Parameters :\n",
    "    cleared_train_data(DataFrame) : pandas dataframe with the whole data\n",
    "    \n",
    "    Returns : \n",
    "    targets(DataFrame) : dataframe with reactivity columns\n",
    "    \"\"\"\n",
    "    \n",
    "    reactivity_columns = cleared_train_data.columns[~cleared_train_data.columns.isin(['sequence','experiment_type'])]\n",
    "    targets = cleared_train_data[reactivity_columns]\n",
    "    \n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705eb222-75fb-4374-b6dc-8cd87512664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reactivity_masking(targets) :\n",
    "    \n",
    "    \"\"\"\n",
    "    Handle Na reactivity values by creating a mask\n",
    "    \n",
    "    Parameters : \n",
    "    targets(DataFrame) : dataframe with reactivity columns\n",
    "    \n",
    "    Returns :\n",
    "    reactivity_mask(Boolean mask) : mask for na reactivity values\n",
    "    \"\"\"\n",
    "    \n",
    "    reactivity_mask = ~np.isnan(targets.values)\n",
    "    return reactivity_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7068ed-2bbe-423a-9e35-56ea93932e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_sets(features, targets, reactivity_mask):\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates the Validation and the training sets\n",
    "    \n",
    "    Parameters :\n",
    "    - features(matrix) : concatenated encoded matrix\n",
    "    - targets(DataFrame) : dataframe with reactivity columns\n",
    "    - reactivity_mask(Boolean mask) : mask for na reactivity values\n",
    "    \n",
    "    Returns :\n",
    "    \n",
    "    - X_train\n",
    "    - X_val\n",
    "    - y_train\n",
    "    - y_val\n",
    "    - mask_train\n",
    "    - mask_val\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, X_val, y_train, y_val, mask_train, mask_val = train_test_split(\n",
    "        features, targets, reactivity_mask, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val, mask_train, mask_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8913f3c7-5173-4a03-8724-73307c234b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_inp(X_train, X_val) :\n",
    "    \"\"\"\n",
    "    Reshape the input format\n",
    "\n",
    "    Parameters:\n",
    "    - X_train: Training feature matrix (e.g., dense matrix)\n",
    "    - X_val: Validation feature matrix (e.g., dense matrix)\n",
    "\n",
    "    Returns:\n",
    "    - X_train_reshaped: Reshaped training data with time step dimension\n",
    "    - X_val_reshaped: Reshaped validation data with time step dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    #Convert dense matrix to dense array \n",
    "    \n",
    "    X_train_dense = X_train.toarray()\n",
    "    X_val_dense = X_val.toarray()\n",
    "    \n",
    "    # Reshape input data to include the time step dimension\n",
    "    timesteps = 1  # Number of time steps (since since we have masked sequences)\n",
    "    input_dim = X_train_dense.shape[1]\n",
    "    X_train_reshaped = X_train_dense.reshape(X_train_dense.shape[0], timesteps, input_dim)\n",
    "    X_val_reshaped = X_val_dense.reshape(X_val_dense.shape[0], timesteps, input_dim)\n",
    "    \n",
    "    return X_val_reshaped, X_val_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b462c16-7266-4cba-a4b6-3489115af55a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
